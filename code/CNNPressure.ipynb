{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNNPressure.ipynb","provenance":[{"file_id":"1zT9SgyX1XMG70mWGAisYxJM7W2ObwhH5","timestamp":1645440831873}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"90AQDPv-kB3_","executionInfo":{"status":"ok","timestamp":1645439067965,"user_tz":-60,"elapsed":23130,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ddf5e2c2-e3ce-4e00-84c8-86363c8476a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Import libraries"],"metadata":{"id":"y1fnDZHxywxO"}},{"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","import pandas as pd"],"metadata":{"id":"vp-mtXVWnImF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# insert your path\n","path='./drive/MyDrive/Colab_Notebooks/Datamining_Project/'"],"metadata":{"id":"eA7cHtCBzSqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Read the dataset with the overall data about pressure."],"metadata":{"id":"MbwXvqjD9Vgz"}},{"cell_type":"code","source":["# only to read data\n","tot = pd.read_csv(path+'tot_pressure.csv',index_col=['Points:0','Points:1','Points:2'])\n","tot_df = tot.T\n","tot = tot_df.to_numpy()"],"metadata":{"id":"uiTOkNFzFizT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define the function to prepare data for the CNN model."],"metadata":{"id":"4oco9MOGG-I5"}},{"cell_type":"code","source":["# split a multivariate sequence into samples\n","def split_sequences(sequences, n_steps):\n","    X, Y = list(), list()\n","    for i in range(len(sequences)+1):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        \n","        # check if we are beyond the dataset\n","        if end_ix > len(sequences)-1:\n","            break\n","\t\t\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n","        X.append(seq_x)\n","        Y.append(seq_y)\n","        \n","    return np.array(X), np.array(Y) # the outputs of the function are, respectively, the input data and the target data of the model"],"metadata":{"id":"6Co5y3gLnUGE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Splitting data into training set - test set"],"metadata":{"id":"c3pEfxsY0fMu"}},{"cell_type":"code","source":["# Training set - Test set\n","# 80% - 20%, choosed chronologically\n","\n","tot_train = tot[:800,:]\n","tot_test = tot[800:,:]"],"metadata":{"id":"NwJIUSEZnbI_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build the model"],"metadata":{"id":"jQ6-OvL50odz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s11oYpzSj6DF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643026370287,"user_tz":-60,"elapsed":11617655,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"outputId":"adfebf55-ff28-4593-a534-c1a3c68488cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["nan\n"]}],"source":["# choose a number of time steps\n","n_steps = 75\n","# convert into input/output\n","X_train, Y_train = split_sequences(tot_train, n_steps)\n","n_features = X_train.shape[2]\n","# define model\n","model = Sequential()\n","model.add(Conv1D(filters=64, kernel_size=2, activation='tanh', input_shape=(n_steps, n_features)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(50, activation='tanh'))\n","model.add(Dense(n_features))\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(X_train, Y_train, epochs=3000, verbose=0)\n","# convert into input/output\n","X_test, Y_test = split_sequences(tot_test, n_steps)"]},{"cell_type":"markdown","source":["Finally compute the prediction"],"metadata":{"id":"bQgR5Xi6Hm4D"}},{"cell_type":"code","source":["Y_pred = model.predict(X_test, verbose=0)"],"metadata":{"id":"7S3Dtz1-Hl8E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save data"],"metadata":{"id":"UGaZB8WRHwgo"}},{"cell_type":"code","source":["# only to save data\n","# pd.DataFrame(Y_pred).to_csv(path + \"Y_pres_cnn.csv\", index=False)"],"metadata":{"id":"GftY5bi4lVgG","executionInfo":{"status":"error","timestamp":1643028868020,"user_tz":-60,"elapsed":1806,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"colab":{"base_uri":"https://localhost:8080/","height":200},"outputId":"61ccb007-8e2c-405f-c054-530272c142b9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-c3393ac7417a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# solo per salvare i dati\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/MyDrive/Colab_Notebooks/Datamining_Project/Y_pred_75.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"]}]},{"cell_type":"code","source":["# only to read data\n","# Y_pred = pd.read_csv(path+'Y_pres_cnn.csv')"],"metadata":{"id":"ZNWc3WjMURLb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create 126 csv files with the predictions."],"metadata":{"id":"VG2FIi0J1WSt"}},{"cell_type":"code","source":["# to save results\n","Y_pred = Y_pred.to_numpy()\n","data_pred=tot_df.T.reset_index()[['Points:0','Points:1','Points:2']]"],"metadata":{"id":"hrsefjx4ZaoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save data: a dataset is created for each second and it contains the prediction for every point\n","for i in range(len(Y_pred)):\n","  j=i+n_steps\n","  if i==0:\n","    data_pred.insert(0,'Predicted p',Y_pred[i])\n","    data_pred.to_csv(path+\"dataCNN/dataPred_\"+str(1000-200+j)+\".csv\", index=False)\n","  if i!=0:\n","    data_pred['Predicted p']=Y_pred[i]\n","    data_pred.to_csv(path+\"dataCNN/dataPred_\"+str(1000-200+j)+\".csv\", index=False)"],"metadata":{"id":"EfLu_OB9PrEZ"},"execution_count":null,"outputs":[]}]}