{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNNvelocity.ipynb","provenance":[{"file_id":"1I98H5EHdJCupQmH2dfezLStFS94G6h00","timestamp":1645441163112}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UpTM4yuNFZTo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645177755574,"user_tz":-60,"elapsed":20188,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"outputId":"49764997-3fbe-44aa-e0a3-d10b3c1c61c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Import libraries"],"metadata":{"id":"y1fnDZHxywxO"}},{"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","import pandas as pd"],"metadata":{"id":"MhYy7i8TGspF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# insert your path\n","path='./drive/MyDrive/Colab_Notebooks/Datamining_Project/'"],"metadata":{"id":"eA7cHtCBzSqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define the function to prepare data for the CNN model."],"metadata":{"id":"yAShgQGqOco0"}},{"cell_type":"code","source":["# split a multivariate sequence into samples\n","def split_sequences(sequences, n_steps):\n","    X, Y = list(), list()\n","    for i in range(len(sequences)+1):\n","        # find the end of this pattern\n","        end_ix = i + n_steps\n","        \n","        # check if we are beyond the dataset\n","        if end_ix > len(sequences)-1:\n","            break\n","\t\t\n","        # gather input and output parts of the pattern\n","        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n","        X.append(seq_x)\n","        Y.append(seq_y)\n","        \n","    return np.array(X), np.array(Y) # the outputs of the function are, respectively, the input data and the target data of the model"],"metadata":{"id":"XWfYSjzhcG-q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","**Component x**"],"metadata":{"id":"aEYiXWMEWra2"}},{"cell_type":"markdown","source":["Read the dataset with the overall data about Ux."],"metadata":{"id":"XJaBhuEg9gt-"}},{"cell_type":"code","source":["# only to read data\n","tot1=pd.read_csv(path+'tot_velocity_x.csv',index_col=['Points:0','Points:1','Points:2'])\n","tot_df1 = tot1.T\n","tot1 = tot_df1.to_numpy()"],"metadata":{"id":"JzZuePxmc7ZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Splitting data into training set - test set"],"metadata":{"id":"c3pEfxsY0fMu"}},{"cell_type":"code","source":["# Training set - Test set\n","# 80% - 20%, choosed chronologically\n","\n","tot_train = tot1[:800,:]\n","tot_test = tot1[800:,:]"],"metadata":{"id":"CmZyPM4QcN2J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build the model"],"metadata":{"id":"jQ6-OvL50odz"}},{"cell_type":"code","source":["# choose a number of time steps\n","n_steps = 75\n","# convert into input/output\n","X_train, Y_train = split_sequences(tot_train, n_steps)\n","# the dataset knows the number of features, e.g. 2\n","n_features = X_train.shape[2]\n","# define model\n","model = Sequential()\n","model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(n_features))\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(X_train, Y_train, epochs=3000, verbose=0)\n","# convert into input/output\n","X_test, Y_test = split_sequences(tot_test, n_steps)"],"metadata":{"id":"hhs-OPkWcQ6d","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1645441297760,"user_tz":-60,"elapsed":713,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"outputId":"71ff314d-1788-4e65-b65d-ef7b4a5c5bfd"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-47f206236bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# convert into input/output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'split_sequences' is not defined"]}]},{"cell_type":"markdown","source":["Finally compute the prediction"],"metadata":{"id":"JeotEPNmQ_PJ"}},{"cell_type":"code","source":["Y_pred = model.predict(X_test, verbose=0)"],"metadata":{"id":"j6q0ztC7Q8wk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save data"],"metadata":{"id":"mWdOCjEgWI2G"}},{"cell_type":"code","source":["# only to save data\n","# pd.DataFrame(Y_pred).to_csv(path+'Y_vel_cnn.csv', index=False)"],"metadata":{"id":"PkDuF5Tw2ZNx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# only to read data\n","# Y_pred = pd.read_csv(path+'Y_vel_cnn.csv')"],"metadata":{"id":"b6ur4qbT2IBD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Update the 126 csv files with the predictions."],"metadata":{"id":"VG2FIi0J1WSt"}},{"cell_type":"code","source":["Y_pred = Y_pred.to_numpy()\n","# update dataset that contains predicted pression with predicted velocity\n","for i in range(len(Y_pred)):\n","  j=n_steps+i\n","  data_pred = pd.read_csv(path+'dataCNN/dataPred_'+str(1000-200+j)+'.csv')\n","  data_pred = data_pred[['Predicted p','Points:0','Points:1','Points:2']]\n","  data_pred.insert(1,'Predicted U:0',Y_pred[i])\n","  data_pred.to_csv(path+\"dataCNN/dataPred_\"+str(1000-200+j)+\".csv\", index=False)"],"metadata":{"id":"8m-ipViP840N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","**Component y**"],"metadata":{"id":"QckOjXkHW4Sb"}},{"cell_type":"markdown","source":["Read the dataset with the overall data about Uy."],"metadata":{"id":"pUqfN29A9kFA"}},{"cell_type":"code","source":["# only to read data\n","tot_df2 = pd.read_csv(path+'tot_velocity_y.csv', index_col=['Points:0','Points:1','Points:2'])\n","tot_df2 = tot_df2.T\n","tot2 = tot_df2.to_numpy()"],"metadata":{"id":"HxHhdHYz77oG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Splitting data into training set - test set"],"metadata":{"id":"70zDs0PB48av"}},{"cell_type":"code","source":["# Training set - Test set\n","# 80% - 20%, choosed chronologically\n","\n","tot_train = tot2[:800,:]\n","tot_test = tot2[800:,:]"],"metadata":{"id":"n_7WKTjI8KVy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build the model"],"metadata":{"id":"UoB4R3Xj4_Hv"}},{"cell_type":"code","source":["# choose a number of time steps\n","n_steps = 75\n","# convert into input/output\n","X_train, Y_train = split_sequences(tot_train, n_steps)\n","# the dataset knows the number of features, e.g. 2\n","n_features = X_train.shape[2]\n","# define model\n","model = Sequential()\n","model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(n_features))\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(X_train, Y_train, epochs=3000, verbose=0)\n","# convert into input/output\n","X_test, Y_test = split_sequences(tot_test, n_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6Mku1eL8MZw","executionInfo":{"status":"ok","timestamp":1642780420421,"user_tz":-60,"elapsed":856783,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"outputId":"3403398a-53f4-404c-b183-dbde2232ad11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5.448012529996049e-07\n"]}]},{"cell_type":"markdown","source":["Finally compute the prediction"],"metadata":{"id":"_027wuxBZjTu"}},{"cell_type":"code","source":["Y_pred = model.predict(X_test, verbose=0)"],"metadata":{"id":"uAz9zoOgZjTv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save data"],"metadata":{"id":"B8_4KTG2ZjTv"}},{"cell_type":"code","source":["# only to save data\n","# pd.DataFrame(Y_pred).to_csv(path+\"Y_vel2_cnn.csv\", index=False)"],"metadata":{"id":"tpFDUEtR8bOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# only to read data\n","# Y_pred = pd.read_csv(path+\"Y_vel2_cnn.csv\")"],"metadata":{"id":"vbhC4Fox8uvf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Update the 126 csv files with the predictions."],"metadata":{"id":"8ofddGxc5WB_"}},{"cell_type":"code","source":["Y_pred = Y_pred.to_numpy()\n","# update dataset that contains predicted pression with predicted velocity\n","for i in range(len(Y_pred)):\n","  j=n_steps+i\n","  data_pred = pd.read_csv(path+'dataCNN/dataPred_'+str(1000-200+j)+'.csv')\n","  data_pred.insert(2,'Predicted U:1',Y_pred[i])\n","  data_pred.to_csv(path+\"dataCNN/dataPred_\"+str(1000-200+j)+\".csv\", index=False)"],"metadata":{"id":"fGJoEyQk-Tgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","**Component z**"],"metadata":{"id":"ksrwT40ZZSYp"}},{"cell_type":"markdown","source":["Read the dataset with the overall data about Uz."],"metadata":{"id":"PENu6e229nC7"}},{"cell_type":"code","source":["# only to read data\n","tot_df3 = pd.read_csv(path+'tot_velocity_z.csv', index_col=['Points:0','Points:1','Points:2'])\n","tot_df3 = tot_df3.T\n","tot3 = tot_df3.to_numpy()"],"metadata":{"id":"DQrNDj4S79My"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Splitting into training set - test set"],"metadata":{"id":"VaLEeS-J5_TH"}},{"cell_type":"code","source":["# Training set - Test set\n","# 80% - 20%, choosed chronologically\n","\n","tot_train = tot3[:800,:]\n","tot_test = tot3[800:,:]"],"metadata":{"id":"X5HzuX3e-w0c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build the model"],"metadata":{"id":"XvglB8la6CE-"}},{"cell_type":"code","source":["# choose a number of time steps\n","n_steps = 75\n","# convert into input/output\n","X_train, Y_train = split_sequences(tot_train, n_steps)\n","# the dataset knows the number of features, e.g. 2\n","n_features = X_train.shape[2]\n","# define model\n","model = Sequential()\n","model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(n_features))\n","model.compile(optimizer='adam', loss='mse')\n","# convert into input/output\n","X_test, Y_test = split_sequences(tot_test, n_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzfctFsr-w0d","executionInfo":{"status":"ok","timestamp":1642782140495,"user_tz":-60,"elapsed":836985,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"outputId":"3ec74d6b-631d-4f7f-cb0d-f9241b67635d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n"]}]},{"cell_type":"markdown","source":["Finally compute the prediction"],"metadata":{"id":"xaLAiISqZxAn"}},{"cell_type":"code","source":["Y_pred = model.predict(X_test, verbose=0)"],"metadata":{"id":"dtl3D5tHZxAo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save data"],"metadata":{"id":"QjFfho4AZxAp"}},{"cell_type":"code","source":["# only to save data\n","# pd.DataFrame(Y_pred).to_csv(path+\"Y_vel3_cnn.csv\", index=False)"],"metadata":{"id":"yIaxY2O--w0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# only to read data\n","# Y_pred = pd.read_csv(path+\"Y_vel3_cnn.csv\")"],"metadata":{"id":"1LjBc_SZ-w0g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Update the 126 csv files with the predictions."],"metadata":{"id":"r3EOmPjh6XA6"}},{"cell_type":"code","source":["Y_pred = Y_pred.to_numpy()\n","# update dataset that contains predicted pression with predicted velocity\n","for i in range(len(Y_pred)):\n","  j=i+n_steps\n","  data_pred = pd.read_csv(path+'dataCNN/dataPred_'+str(1000-200+j)+'.csv')\n","  data_pred.insert(3,'Predicted U:2',Y_pred[i])\n","  data_pred.to_csv(path+\"dataCNN/dataPred_\"+str(1000-200+j)+\".csv\", index=False)"],"metadata":{"id":"xIkwZHsRQ8fP","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1645056098139,"user_tz":-60,"elapsed":440,"user":{"displayName":"Anna Nava","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07316521851738717583"}},"outputId":"7e8777b3-dfb1-4b85-daf8-07cb62b63258"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-faf5ba682b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdata_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drive/MyDrive/Colab_Notebooks/Datamining_Project/dataPredAdj/dataPred_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdata_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Predicted U:2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdata_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/MyDrive/Colab_Notebooks/Datamining_Project/dataPredAdj/dataPred_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4416\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4418\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4419\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length of values (1001) does not match length of index (11160)"]}]}]}